{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "442ec057",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b21361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import json\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.layers import Dense, Activation,Flatten,Conv2D,Dropout,MaxPooling2D,AveragePooling2D,BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import MobileNetV3Small, EfficientNetB0\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df82918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dd4d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78d24e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-13.4.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.13.0\n",
      "\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print()\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc183d74",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848353fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "train_data = shuffle(train_data,random_state = 0)\n",
    "train_data['label'] = pd.Series(train_data['label'], dtype=\"string\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406070e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = open('./data/label_num_to_disease_map.json')\n",
    "label_names = json.load(label_names)\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Classification\"] = train_data[\"label\"].apply(lambda x: label_names.get(x))\n",
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7180772b",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44098f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = train_data.groupby('label', as_index=False).count()\n",
    "label_count.rename(columns={'image_id': 'Count', 'label': 'Label'}, inplace=True)\n",
    "label_count['Label'] = label_count['Label'].apply(lambda x: label_names[x])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "font1 = {'family': 'Times New Roman','weight': 'bold','style':'normal','size': 20}\n",
    "ax.set_xlabel('Type of disease',font1)\n",
    "ax.set_ylabel('Count',font1)\n",
    "ax = sns.barplot(x=label_count['Count'], y=label_count['Label'], palette='viridis')\n",
    "ax.tick_params(labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_ids, labels):\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    \n",
    "    for i, (image_id, label) in enumerate(zip(image_ids, labels)):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join('./data/train_images', image_id))\n",
    "            if img is None:\n",
    "                raise FileNotFoundError(f\"Image not found: {image_id}\")\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Class: {label}\", fontsize=12)\n",
    "            plt.axis(\"off\")\n",
    "        except Exception as e:\n",
    "            # Handle the error gracefully\n",
    "            print(f\"Error loading image '{image_id}': {e}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "samples = train_data.sample(9, random_state=0)\n",
    "image_ids = samples['image_id'].values\n",
    "labels = samples['Classification'].values\n",
    "\n",
    "show_image(image_ids, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    try:\n",
    "        img_bgr = cv2.imread(path)\n",
    "        img_rgb = img_bgr[:, :, ::-1]\n",
    "        return img_rgb\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image '{path}': {e}\")\n",
    "        return None\n",
    "\n",
    "# explore the pixels of cassava leaf pictures\n",
    "img_folder = Path('data/train_images')\n",
    "if img_folder.exists():\n",
    "    img_names = img_folder.glob('*')\n",
    "    plt.figure(figsize=(12, 8), dpi=800)\n",
    "    pbar = tqdm(img_names, total=len(train_data))\n",
    "    for img_name in pbar:\n",
    "        img = load_img(img_name.as_posix())\n",
    "        if img is not None:\n",
    "            # here use the calchist method in cv2 to show the histogram of photo pixels\n",
    "            hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "            plt.plot(hist)\n",
    "        else:\n",
    "            print(f\"Skipping image: '{img_name}'\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Directory containing images does not exist.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bc6b58b",
   "metadata": {},
   "source": [
    "## Healthy & Cassava Leaf Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df021f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Healthy_Cassava = train_data[train_data['Classification'] == 'Healthy']['image_id'].to_list()\n",
    "\n",
    "CMD_Cassava = train_data[train_data['Classification'] == 'Cassava Mosaic Disease (CMD)']['image_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20239417)\n",
    "\n",
    "base_path = Path('data')\n",
    "train_img_dir =  base_path/'train_images'\n",
    "\n",
    "random_images=[]\n",
    "plt.figure(figsize=(16,12))\n",
    "for i in range(9):\n",
    "    random_images.append(np.random.choice(Healthy_Cassava))\n",
    "\n",
    "for i in range(9): \n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = plt.imread(train_img_dir/random_images[i])\n",
    "    plt.imshow(img)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16,8))\n",
    "f.add_subplot(1,2, 1)\n",
    "\n",
    "font2 = {'family': 'Times New Roman','weight': 'bold','style':'normal','size': 14}\n",
    "raw_image = plt.imread(train_img_dir/Healthy_Cassava[2])\n",
    "plt.imshow(raw_image, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Healthy Image',font2)\n",
    "print(f\"Image dimensions:  {raw_image.shape[0],raw_image.shape[1]}\")\n",
    "print(f\"Maximum pixel value : {raw_image.max():.1f} ; Minimum pixel value:{raw_image.min():.1f}\")\n",
    "print(f\"Mean value of the pixels : {raw_image.mean():.1f} ; Standard deviation : {raw_image.std():.1f}\")\n",
    "\n",
    "f.add_subplot(1,2, 2)\n",
    "#  plt.hist(raw_image[:, :, 0].ravel(), bins=256, color='red', alpha=0.5): This line creates a histogram for the red channel of the image (raw_image) and \n",
    "# visualizes the pixel intensity distribution. It uses raw_image[:, :, 0] to extract the red channel of the image, and \n",
    "# ravel() is used to flatten the 2D array into a 1D array (necessary for plotting the histogram). \n",
    "# The bins=256 parameter specifies that the histogram will have 256 bins, which means that the intensity values will be grouped into 256 intervals. \n",
    "# The color='red' parameter sets the color of the histogram to red, and alpha=0.5 sets the transparency of the histogram to 50%, making it semi-transparent.\n",
    "plt.hist(raw_image[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\n",
    "plt.hist(raw_image[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\n",
    "plt.hist(raw_image[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\n",
    "plt.xlabel('Intensity Value',font2)\n",
    "plt.ylabel('Count',font2)\n",
    "plt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbc334",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageArray = []\n",
    "for i in range(len(Healthy_Cassava)):\n",
    "    try:\n",
    "        img = cv2.imread(str(train_img_dir / Healthy_Cassava[i]))\n",
    "        if img is not None:\n",
    "            imageArray.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            print(f\"Failed to load image: {train_img_dir / Healthy_Cassava[i]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {train_img_dir / Healthy_Cassava[i]} - {e}\")\n",
    "\n",
    "red_values = []\n",
    "green_values = []\n",
    "blue_values = []\n",
    "values = []\n",
    "\n",
    "for i in range(len(imageArray)):\n",
    "    red_values.append(np.mean(imageArray[i][:, :, 0]))\n",
    "    green_values.append(np.mean(imageArray[i][:, :, 1]))\n",
    "    blue_values.append(np.mean(imageArray[i][:, :, 2]))\n",
    "    values.append(np.mean(imageArray[i]))\n",
    "\n",
    "hist_data = [red_values, green_values, blue_values, values]\n",
    "group_labels = ['Red', 'Green', 'Blue', 'All']\n",
    "\n",
    "fig = ff.create_distplot(hist_data, group_labels,colors = ['red', 'green','blue','grey'])\n",
    "fig.update_layout(template = 'plotly_white', title_text = 'Channel Distribution - Healthy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "figData = []\n",
    "for i, name in zip(range(3), ['Red', 'Green', 'Blue']):\n",
    "    trace = go.Box(y = hist_data[i], name = name, boxpoints='all', marker_color  = name)\n",
    "    figData.append(trace)\n",
    "\n",
    "fig = go.Figure(figData)\n",
    "fig.update_layout(title_text = 'Pixel Intensity Distribution - health leaf', template = 'plotly_white')\n",
    "fig.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5d00bb5",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"label\"] = train_data[\"label\"].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ab88be2",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8598473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=40, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2,    \n",
    "    horizontal_flip = True, \n",
    "    vertical_flip = True,\n",
    "    validation_split = 0.2,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "val_data_gen = ImageDataGenerator(validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_iter = train_data_gen.flow_from_dataframe(\n",
    "    dataframe=train_data, directory = \"data/train_images\", seed = 0, x_col = \"image_id\", y_col = \"label\", interpolation = 'nearest', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), class_mode = \"categorical\", batch_size = BATCH_SIZE, shuffle = True, subset = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deee6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_iter = val_data_gen.flow_from_dataframe(\n",
    "    dataframe=train_data, directory = \"data/train_images\", seed = 0, x_col = \"image_id\",y_col = \"label\", interpolation = 'nearest', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), class_mode = \"categorical\", batch_size = BATCH_SIZE, shuffle = True, subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d51c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"label\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbd565ef",
   "metadata": {},
   "source": [
    "The choice between Categorical Cross Entropy and Sparse Categorical Cross Entropy depends on how the class labels are represented:\n",
    "\n",
    "Categorical Cross Entropy (Softmax Cross Entropy):\n",
    "\n",
    "    Used when class labels are one-hot encoded.\n",
    "    The model's output has the same number of units as the number of classes, and each unit's activation represents the probability of the input belonging to that class.\n",
    "    The true labels are provided in one-hot encoded format, where only one element is 1, and the rest are 0s.\n",
    "    Appropriate when there are a small number of classes or memory is not a concern.\n",
    "\n",
    "Sparse Categorical Cross Entropy:\n",
    "\n",
    "    Used when class labels are represented as integers (e.g., 0, 1, 2, etc.).\n",
    "    The model's output still has the same number of units as the number of classes, but the true labels are provided as integers instead of one-hot encoded arrays.\n",
    "    The integer class labels directly specify the class of each input sample.\n",
    "    Appropriate when there are a large number of classes, and one-hot encoding of labels might be memory-intensive.\n",
    "\n",
    "In our case, train_data dataframe's \"label\" column contains integer class labels (e.g., 0, 1, 2, etc.), so we can use Sparse Categorical Cross Entropy as the loss function. It will work effectively and avoid the overhead of one-hot encoding the labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d02b853",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optimizer = Adam(lr=0.0105)\n",
    "model_loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False, \n",
    "                                                     label_smoothing=0.0001, \n",
    "                                                     name='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model_with_base_EfficientNetB0():\n",
    "    conv_base = EfficientNetB0( \n",
    "        include_top = False, \n",
    "        weights = None,\n",
    "        input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    #conv_base.trainable = False\n",
    "    model = conv_base.output\n",
    "    model = layers.GlobalAveragePooling2D()(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = layers.Dense(NCLASSES, activation = \"softmax\")(model)\n",
    "    model = Model(conv_base.input, model)\n",
    "    model.compile(optimizer = model_optimizer,\n",
    "                  loss = model_loss,\n",
    "                  metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = custom_model_with_base_EfficientNetB0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('weights/Cassava_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af924c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe214e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tf.keras.saving.load_model('weights/EfficientNetB3-imageNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60ed0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Model has 5 layers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Our Model has %d layers' %len(my_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab3ae27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m STEPS_PER_EPOCH  \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_data)\u001b[39m*\u001b[39m\u001b[39m0.8\u001b[39m \u001b[39m/\u001b[39m BATCH_SIZE\n\u001b[1;32m      2\u001b[0m VALIDATION_STEPS \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_data)\u001b[39m*\u001b[39m\u001b[39m0.2\u001b[39m \u001b[39m/\u001b[39m BATCH_SIZE\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH  = len(train_data)*0.8 / BATCH_SIZE\n",
    "VALIDATION_STEPS = len(train_data)*0.2 / BATCH_SIZE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9de0d62",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2de2081",
   "metadata": {},
   "source": [
    "## Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(  monitor='val_loss', \n",
    "                                factor=0.2,\n",
    "                                patience=2, \n",
    "                                min_lr=1e-6, \n",
    "                                mode='min', \n",
    "                                verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", \n",
    "                               mode = \"min\", \n",
    "                               patience = 2, \n",
    "                               restore_best_weights=True, \n",
    "                               verbose= 1)\n",
    "\n",
    "check_point = ModelCheckpoint( \"clf_best_model.h5\", \n",
    "                                monitor = 'val_loss',\n",
    "                                mode = 'min', \n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ede0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = my_model.fit(\n",
    "    train_df_iter,\n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    validation_data = val_df_iter,\n",
    "    validation_steps = VALIDATION_STEPS,\n",
    "    epochs = 10, \n",
    "    callbacks = [early_stopping, reduce_lr, check_point]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb043bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in my_model.layers:\n",
    "    # print(\"{0:40s}, {1:<10s}\".format(l.name, \"True\" if l.trainable == True else \"False\"))\n",
    "    l.trainable = True\n",
    "\n",
    "my_model.compile(   loss=model_loss, \n",
    "                    optimizer=Adam(learning_rate=1e-2), \n",
    "                    metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_history = my_model.fit(  \n",
    "    train_df_iter, \n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    validation_data = val_df_iter,\n",
    "    validation_steps = VALIDATION_STEPS,\n",
    "    epochs = 3, \n",
    "    callbacks = [early_stopping, reduce_lr, check_point])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d87c904",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models Evaluation \n",
    "freeze_accuracy = history.history[\"acc\"]\n",
    "freeze_v_accuracy = history.history[\"val_acc\"]\n",
    "\n",
    "freeze_loss = history.history[\"loss\"]\n",
    "freeze_v_loss = history.history[\"val_loss\"]\n",
    "\n",
    "acc = fine_tuning_history.history[\"acc\"]\n",
    "v_acc = fine_tuning_history.history[\"val_acc\"]\n",
    "\n",
    "loss = fine_tuning_history.history[\"loss\"]\n",
    "v_loss = fine_tuning_history.history[\"val_loss\"]\n",
    "\n",
    "# Plot four main Evaluation criterions\n",
    "epochs_10 = range(6)\n",
    "epochs_3 = range(3)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_10, freeze_accuracy, label = \"Training Set freeze_accuracy\")\n",
    "plt.plot(epochs_10, freeze_v_accuracy, label = \"Validation Set freeze_v_accuracy\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.title(\"Freezed Training and Validation Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_10, freeze_loss, label = \"Training Set freeze_loss\")\n",
    "plt.plot(epochs_10, freeze_v_loss, label = \"Validation Set freeze_v_loss\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.title(\"Freezed Training and Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_3, acc, label = \"Training Set Accuracy\")\n",
    "plt.plot(epochs_3, v_acc, label = \"Validation Set Accuracy\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_3, loss, label = \"Training Set Loss\")\n",
    "plt.plot(epochs_3, v_loss, label = \"Validation Set Loss\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cb89bc8",
   "metadata": {},
   "source": [
    "# Convert and save as tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49fe11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/yq/qh4ny6ms3kz0yqqj4q2gqkn00000gn/T/tmp7s7rwan1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/yq/qh4ny6ms3kz0yqqj4q2gqkn00000gn/T/tmp7s7rwan1/assets\n",
      "2023-07-24 23:05:38.204826: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-24 23:05:38.205181: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-24 23:05:38.206962: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/yq/qh4ny6ms3kz0yqqj4q2gqkn00000gn/T/tmp7s7rwan1\n",
      "2023-07-24 23:05:38.266305: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-07-24 23:05:38.266323: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/yq/qh4ny6ms3kz0yqqj4q2gqkn00000gn/T/tmp7s7rwan1\n",
      "2023-07-24 23:05:38.476216: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-24 23:05:39.910476: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/yq/qh4ny6ms3kz0yqqj4q2gqkn00000gn/T/tmp7s7rwan1\n",
      "2023-07-24 23:05:40.307969: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 2101017 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(my_model)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac323c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "with open('EfficientNetB3-ImageNet2.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "134b4fa7",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429489bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "sample_sub_csv = pd.read_csv('data/sample_submission.csv')\n",
    "classes = [ \"Cassava Bacterial Blight (CBB)\", \n",
    "           \"Cassava Brown Streak Disease (CBSD)\", \n",
    "           \"Cassava Green Mottle (CGM)\", \n",
    "           \"Cassava Mosaic Disease (CMD)\", \n",
    "           \"Healthy\" ]\n",
    "for image in sample_sub_csv.image_id:\n",
    "    img = tf.keras.preprocessing.image.load_img('data/test_images/' + image)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.preprocessing.image.smart_resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img = tf.reshape(img, (-1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    prediction = my_model.predict(img)\n",
    "    print(f\"prediction: {prediction}, type: {type(prediction)}, shape: {prediction.shape}\")\n",
    "    print(f\"Class: {classes[np.argmax(prediction)]}\")\n",
    "    preds.append(np.argmax(prediction))\n",
    "\n",
    "final_submission = pd.DataFrame({'image_id': sample_sub_csv.image_id, 'label': preds})\n",
    "final_submission.to_csv('submission.csv', index=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c67206f",
   "metadata": {},
   "source": [
    "prediction: [[0.00491412 0.04006411 0.09978469 0.67050004 0.18473706]], \n",
    "\n",
    "type: <class 'numpy.ndarray'>, shape: (1, 5)\n",
    "\n",
    "\n",
    "Class: Cassava Mosaic Disease (CMD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76db9ef4",
   "metadata": {},
   "source": [
    "prediction: [[0.02368715 0.03569924 0.01429282 0.8705369  0.0557838 ]], \n",
    "\n",
    "type: <class 'numpy.ndarray'>, shape: (1, 5)\n",
    "\n",
    "\n",
    "Class: Cassava Mosaic Disease (CMD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassava-leaf-clf-TF",
   "language": "python",
   "name": "cassava-leaf-clf-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
